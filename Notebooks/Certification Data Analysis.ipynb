{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96545d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0155c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "batch_size = 50\n",
    "root_dir = r'/Users/patrickpynadath/PycharmProjects/RobustnessResearch/OriginalWork'\n",
    "trainset = torchvision.datasets.CIFAR10(root=root_dir, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=root_dir, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24469a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_classifier_arch import simple_conv_net \n",
    "net = simple_conv_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e0fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.207\n",
      "[1,  4000] loss: 1.829\n",
      "[1,  6000] loss: 1.650\n",
      "[1,  8000] loss: 1.567\n",
      "[1, 10000] loss: 1.477\n",
      "[1, 12000] loss: 1.441\n",
      "[2,  2000] loss: 1.381\n",
      "[2,  4000] loss: 1.365\n",
      "[2,  6000] loss: 1.325\n",
      "[2,  8000] loss: 1.329\n",
      "[2, 10000] loss: 1.295\n",
      "[2, 12000] loss: 1.262\n",
      "[3,  2000] loss: 1.211\n",
      "[3,  4000] loss: 1.199\n",
      "[3,  6000] loss: 1.195\n",
      "[3,  8000] loss: 1.184\n",
      "[3, 10000] loss: 1.175\n",
      "[3, 12000] loss: 1.189\n",
      "[4,  2000] loss: 1.083\n",
      "[4,  4000] loss: 1.087\n",
      "[4,  6000] loss: 1.115\n",
      "[4,  8000] loss: 1.108\n",
      "[4, 10000] loss: 1.086\n",
      "[4, 12000] loss: 1.104\n",
      "[5,  2000] loss: 1.007\n",
      "[5,  4000] loss: 1.028\n",
      "[5,  6000] loss: 1.022\n",
      "[5,  8000] loss: 1.033\n",
      "[5, 10000] loss: 1.038\n",
      "[5, 12000] loss: 1.030\n",
      "[6,  2000] loss: 0.935\n",
      "[6,  4000] loss: 0.948\n",
      "[6,  6000] loss: 0.974\n",
      "[6,  8000] loss: 0.979\n",
      "[6, 10000] loss: 0.993\n",
      "[6, 12000] loss: 0.969\n",
      "[7,  2000] loss: 0.873\n",
      "[7,  4000] loss: 0.918\n",
      "[7,  6000] loss: 0.931\n",
      "[7,  8000] loss: 0.935\n",
      "[7, 10000] loss: 0.919\n",
      "[7, 12000] loss: 0.955\n",
      "[8,  2000] loss: 0.850\n",
      "[8,  4000] loss: 0.894\n",
      "[8,  6000] loss: 0.875\n",
      "[8,  8000] loss: 0.886\n",
      "[8, 10000] loss: 0.898\n",
      "[8, 12000] loss: 0.908\n",
      "[9,  2000] loss: 0.787\n",
      "[9,  4000] loss: 0.841\n",
      "[9,  6000] loss: 0.834\n",
      "[9,  8000] loss: 0.848\n",
      "[9, 10000] loss: 0.857\n",
      "[9, 12000] loss: 0.884\n",
      "[10,  2000] loss: 0.772\n",
      "[10,  4000] loss: 0.803\n",
      "[10,  6000] loss: 0.814\n",
      "[10,  8000] loss: 0.816\n",
      "[10, 10000] loss: 0.846\n",
      "[10, 12000] loss: 0.855\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs = 100\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62790cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1 | iteration: 1000 | progress: [50000/50000] (100%) | loss => total: 2093.0330 / re: 2091.816 / kl: 1.217: : 1000it [00:40, 24.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#############\n",
      "# checkpoint!\n",
      "#############\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 | iteration: 2562 | progress: [50000/50000] (100%) | loss => total: 2092.9136 / re: 2091.417 / kl: 1.497: : 1000it [00:38, 25.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#############\n",
      "# checkpoint!\n",
      "#############\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 | iteration: 4124 | progress: [50000/50000] (100%) | loss => total: 2065.4065 / re: 2063.729 / kl: 1.678: : 1000it [00:40, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#############\n",
      "# checkpoint!\n",
      "#############\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vae_arch import VAE\n",
    "from train_vae import train_model\n",
    "import torch.optim as optim\n",
    "\n",
    "vae = VAE(label=\"test\", image_size=32, channel_num=3, kernel_num=50, z_size=50)\n",
    "train_model(vae, trainloader, len(trainset), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b4c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm, binom_test\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import torch\n",
    "from vae_arch import VAE\n",
    "\n",
    "\n",
    "class Smooth(object):\n",
    "    \"\"\"A smoothed classifier g \"\"\"\n",
    "\n",
    "    # to abstain, Smooth returns this int\n",
    "    ABSTAIN = -1\n",
    "\n",
    "    def __init__(self, base_classifier: torch.nn.Module, num_classes: int, sigma: float):\n",
    "        \"\"\"\n",
    "        :param base_classifier: maps from [batch x channel x height x width] to [batch x num_classes]\n",
    "        :param num_classes:\n",
    "        :param sigma: the noise level hyperparameter\n",
    "        \"\"\"\n",
    "        self.base_classifier = base_classifier\n",
    "        self.num_classes = num_classes\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def certify(self, x: torch.tensor, n0: int, n: int, alpha: float, batch_size: int) -> (int, float):\n",
    "        \"\"\" Monte Carlo algorithm for certifying that g's prediction around x is constant within some L2 radius.\n",
    "        With probability at least 1 - alpha, the class returned by this method will equal g(x), and g's prediction will\n",
    "        robust within a L2 ball of radius R around x.\n",
    "\n",
    "        :param x: the input [channel x height x width]\n",
    "        :param n0: the number of Monte Carlo samples to use for selection\n",
    "        :param n: the number of Monte Carlo samples to use for estimation\n",
    "        :param alpha: the failure probability\n",
    "        :param batch_size: batch size to use when evaluating the base classifier\n",
    "        :return: (predicted class, certified radius)\n",
    "                 in the case of abstention, the class will be ABSTAIN and the radius 0.\n",
    "        \"\"\"\n",
    "        self.base_classifier.eval()\n",
    "        # draw samples of f(x+ epsilon)\n",
    "        counts_selection = self._sample_noise(x, n0, batch_size)\n",
    "        # use these samples to take a guess at the top class\n",
    "        cAHat = counts_selection.argmax().item()\n",
    "        # draw more samples of f(x + epsilon)\n",
    "        counts_estimation = self._sample_noise(x, n, batch_size)\n",
    "        # use these samples to estimate a lower bound on pA\n",
    "        nA = counts_estimation[cAHat].item()\n",
    "        pABar = self._lower_confidence_bound(nA, n, alpha)\n",
    "        if pABar < 0.5:\n",
    "            return Smooth.ABSTAIN, 0.0\n",
    "        else:\n",
    "            radius = self.sigma * norm.ppf(pABar)\n",
    "            return cAHat, radius\n",
    "\n",
    "    def predict(self, x: torch.tensor, n: int, alpha: float, batch_size: int) -> int:\n",
    "        \"\"\" Monte Carlo algorithm for evaluating the prediction of g at x.  With probability at least 1 - alpha, the\n",
    "        class returned by this method will equal g(x).\n",
    "\n",
    "        This function uses the hypothesis test described in https://arxiv.org/abs/1610.03944\n",
    "        for identifying the top category of a multinomial distribution.\n",
    "\n",
    "        :param x: the input [channel x height x width]\n",
    "        :param n: the number of Monte Carlo samples to use\n",
    "        :param alpha: the failure probability\n",
    "        :param batch_size: batch size to use when evaluating the base classifier\n",
    "        :return: the predicted class, or ABSTAIN\n",
    "        \"\"\"\n",
    "        self.base_classifier.eval()\n",
    "        counts = self._sample_noise(x, n, batch_size)\n",
    "        top2 = counts.argsort()[::-1][:2]\n",
    "        count1 = counts[top2[0]]\n",
    "        count2 = counts[top2[1]]\n",
    "        if binom_test(count1, count1 + count2, p=0.5) > alpha:\n",
    "            return Smooth.ABSTAIN\n",
    "        else:\n",
    "            return top2[0]\n",
    "\n",
    "    def _sample_noise(self, x: torch.tensor, num: int, batch_size) -> np.ndarray:\n",
    "        \"\"\" Sample the base classifier's prediction under noisy corruptions of the input x.\n",
    "\n",
    "        :param x: the input [channel x width x height]\n",
    "        :param num: number of samples to collect\n",
    "        :param batch_size:\n",
    "        :return: an ndarray[int] of length num_classes containing the per-class counts\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            counts = np.zeros(self.num_classes, dtype=int)\n",
    "            for _ in range(ceil(num / batch_size)):\n",
    "                this_batch_size = min(batch_size, num)\n",
    "                num -= this_batch_size\n",
    "\n",
    "                batch = x.repeat((this_batch_size, 1, 1, 1))\n",
    "                noise = torch.randn_like(batch) * self.sigma\n",
    "                predictions = self.base_classifier(batch + noise).argmax(1)\n",
    "                counts += self._count_arr(predictions.cpu().numpy(), self.num_classes)\n",
    "            return counts\n",
    "\n",
    "    def _count_arr(self, arr: np.ndarray, length: int) -> np.ndarray:\n",
    "        counts = np.zeros(length, dtype=int)\n",
    "        for idx in arr:\n",
    "            counts[idx] += 1\n",
    "        return counts\n",
    "\n",
    "    def _lower_confidence_bound(self, NA: int, N: int, alpha: float) -> float:\n",
    "        \"\"\" Returns a (1 - alpha) lower confidence bound on a bernoulli proportion.\n",
    "\n",
    "        This function uses the Clopper-Pearson method.\n",
    "\n",
    "        :param NA: the number of \"successes\"\n",
    "        :param N: the number of total draws\n",
    "        :param alpha: the confidence level\n",
    "        :return: a lower bound on the binomial proportion which holds true w.p at least (1 - alpha) over the samples\n",
    "        \"\"\"\n",
    "        return proportion_confint(NA, N, alpha=2 * alpha, method=\"beta\")[0]\n",
    "\n",
    "\n",
    "class SmoothVAE(Smooth):\n",
    "    ABSTAIN = -1\n",
    "\n",
    "    def __init__(self, base_classifier: torch.nn.Module, num_classes: int, sigma: float, trained_VAE: VAE):\n",
    "        super().__init__(base_classifier, num_classes, sigma)\n",
    "        # needs to be trained on the same set as the base classifier\n",
    "        self.trained_VAE = trained_VAE\n",
    "\n",
    "    def _sample_noise_vae(self, x: torch.tensor, num: int, batch_size) -> np.ndarray:\n",
    "        # getting the representation of x within the latent space\n",
    "\n",
    "        encoded = self.trained_VAE.encoder(x[None, :])\n",
    "        z_mean, z_logvar = self.trained_VAE.q(encoded)\n",
    "        z_proj = self.trained_VAE.project(z_mean)\n",
    "        with torch.no_grad():\n",
    "            counts = np.zeros(self.num_classes, dtype=int)\n",
    "            for _ in range(ceil(num / batch_size)):\n",
    "                this_batch_size = min(batch_size, num)\n",
    "                num -= this_batch_size\n",
    "\n",
    "                batch = z_proj.repeat((this_batch_size, 1, 1, 1))\n",
    "                noise = torch.randn_like(batch) * self.sigma\n",
    "                predictions = self.base_classifier(self.trained_VAE.decoder(batch + noise)).argmax(1)\n",
    "                counts += self._count_arr(predictions.cpu().numpy(), self.num_classes)\n",
    "            return counts\n",
    "    \n",
    "    def predict(self, x: torch.tensor, n: int, alpha: float, batch_size: int) -> int:\n",
    "        \"\"\" Monte Carlo algorithm for evaluating the prediction of g at x.  With probability at least 1 - alpha, the\n",
    "        class returned by this method will equal g(x).\n",
    "\n",
    "        This function uses the hypothesis test described in https://arxiv.org/abs/1610.03944\n",
    "        for identifying the top category of a multinomial distribution.\n",
    "\n",
    "        :param x: the input [channel x height x width]\n",
    "        :param n: the number of Monte Carlo samples to use\n",
    "        :param alpha: the failure probability\n",
    "        :param batch_size: batch size to use when evaluating the base classifier\n",
    "        :return: the predicted class, or ABSTAIN\n",
    "        \"\"\"\n",
    "        self.base_classifier.eval()\n",
    "        counts = self._sample_noise_vae(x, n, batch_size)\n",
    "        top2 = counts.argsort()[::-1][:2]\n",
    "        count1 = counts[top2[0]]\n",
    "        count2 = counts[top2[1]]\n",
    "        if binom_test(count1, count1 + count2, p=0.5) > alpha:\n",
    "            return Smooth.ABSTAIN\n",
    "        else:\n",
    "            return top2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db1a17d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certifying Smooth Classifier with sigma = 0.12\n",
      "Certifying Smooth Classifier with sigma = 0.25\n",
      "Certifying Smooth Classifier with sigma = 0.5\n",
      "Certifying Smooth Classifier with sigma = 1\n"
     ]
    }
   ],
   "source": [
    "from certification import certify_classifier\n",
    "# need to generate the certification results for varying sigma\n",
    "sigmas = [.12, .25, .5, 1]\n",
    "\n",
    "# setting the parameters for the certification algorithm \n",
    "num_classes = len(classes)\n",
    "skip_examples = 20\n",
    "max_examples = 1000\n",
    "alpha = .05\n",
    "n0 = 100\n",
    "n=1000\n",
    "batch = 1\n",
    "base_file_name = \"cert_results_sigma_vae\"\n",
    "for s in sigmas:\n",
    "    print(f\"\"\"Certifying Smooth Classifier with sigma = {s}\"\"\")\n",
    "    out_file_name = base_file_name + str(s)\n",
    "    certify_classifier(net, testset, num_classes, out_file_name, skip_examples, max_examples, s, alpha, batch, n0, n, use_vae = False, trained_vae = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f93fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_github_result import generate_accuracy_vs_radii_graph\n",
    "generate_accuracy_vs_radii_graph(base_file_name, sigmas, \"baseline_smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e8d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f9650a89870>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to visualize peturbatins in sample space translated to latent \n",
    "# sample randomly n samples \n",
    "\n",
    "\n",
    "\n",
    "# get latent representations for each x \n",
    "\n",
    "# peturb x by random samples \n",
    "# put through encoder \n",
    "# compare result of the encoded peturbations to the original latent representation \n",
    "\n",
    "# NO NEED TO PETURB THE LATENT INPUTS \n",
    "# put through decoder \n",
    "# compare to the original sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4697ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working in numpy bc better compatability with matplot \n",
    "import numpy as np \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 100\n",
    "root_dir = r'/Users/patrickpynadath/PycharmProjects/RobustnessResearch/OriginalWork'\n",
    "trainset = torchvision.datasets.CIFAR10(root=root_dir, train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=root_dir, train=False,\n",
    "                                       download=False, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "cur_batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a980ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num samples refers to the number of samples used to estimate the latent representation\n",
    "def latent_peturbation_analysis(x, trained_vae):\n",
    "    def get_z(x): \n",
    "        encoded = trained_vae.encoder(torch.tensor(x[None, :]).float())\n",
    "        mean, logvar = trained_vae.q(encoded)\n",
    "        z_proj = trained_vae.project(mean).view(-1, trained_vae.kernel_num,\n",
    "                                        trained_vae.feature_size,\n",
    "                                        trained_vae.feature_size,)\n",
    "        return z_proj.detach().numpy()\n",
    "\n",
    "    delta = np.random.normal(size=x.shape)\n",
    "    z = get_z(x)\n",
    "    peturb_z = get_z(x + delta) \n",
    "    latent_delta = np.random.normal(size = z.shape)\n",
    "    peturb_x = trained_vae.decoder(torch.tensor(z + latent_delta).float()).detach().numpy() \n",
    "    return x, z, peturb_x, peturb_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c472888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Norm of latent representation (l2): 15.456676483154297\n",
      "Norm of latent representation (linfty): 2.004953622817993\n",
      "1\n",
      "Norm of latent representation (l2): 9.844366073608398\n",
      "Norm of latent representation (linfty): 1.447946548461914\n",
      "2\n",
      "Norm of latent representation (l2): 15.00534439086914\n",
      "Norm of latent representation (linfty): 1.534693956375122\n",
      "3\n",
      "Norm of latent representation (l2): 27.785247802734375\n",
      "Norm of latent representation (linfty): 5.722641468048096\n",
      "4\n",
      "Norm of latent representation (l2): 16.67546844482422\n",
      "Norm of latent representation (linfty): 2.2640867233276367\n",
      "5\n",
      "Norm of latent representation (l2): 15.137807846069336\n",
      "Norm of latent representation (linfty): 1.6010128259658813\n",
      "6\n",
      "Norm of latent representation (l2): 16.803791046142578\n",
      "Norm of latent representation (linfty): 2.725893974304199\n",
      "7\n",
      "Norm of latent representation (l2): 13.77648639678955\n",
      "Norm of latent representation (linfty): 1.6172987222671509\n",
      "8\n",
      "Norm of latent representation (l2): 17.5495662689209\n",
      "Norm of latent representation (linfty): 2.7909772396087646\n",
      "9\n",
      "Norm of latent representation (l2): 16.78642463684082\n",
      "Norm of latent representation (linfty): 1.7981666326522827\n",
      "10\n",
      "Norm of latent representation (l2): 14.058480262756348\n",
      "Norm of latent representation (linfty): 1.673258662223816\n",
      "11\n",
      "Norm of latent representation (l2): 17.92299461364746\n",
      "Norm of latent representation (linfty): 2.0467257499694824\n",
      "12\n",
      "Norm of latent representation (l2): 10.94843864440918\n",
      "Norm of latent representation (linfty): 1.2738908529281616\n",
      "13\n",
      "Norm of latent representation (l2): 17.8439998626709\n",
      "Norm of latent representation (linfty): 1.6813193559646606\n",
      "14\n",
      "Norm of latent representation (l2): 10.381209373474121\n",
      "Norm of latent representation (linfty): 1.4450137615203857\n",
      "15\n",
      "Norm of latent representation (l2): 14.821159362792969\n",
      "Norm of latent representation (linfty): 2.3720204830169678\n",
      "16\n",
      "Norm of latent representation (l2): 14.192354202270508\n",
      "Norm of latent representation (linfty): 1.552337884902954\n",
      "17\n",
      "Norm of latent representation (l2): 14.745827674865723\n",
      "Norm of latent representation (linfty): 1.6218715906143188\n",
      "18\n",
      "Norm of latent representation (l2): 19.78788185119629\n",
      "Norm of latent representation (linfty): 1.958162546157837\n",
      "19\n",
      "Norm of latent representation (l2): 15.502338409423828\n",
      "Norm of latent representation (linfty): 1.6744755506515503\n",
      "20\n",
      "Norm of latent representation (l2): 16.77985191345215\n",
      "Norm of latent representation (linfty): 2.2337307929992676\n",
      "21\n",
      "Norm of latent representation (l2): 10.265982627868652\n",
      "Norm of latent representation (linfty): 1.1855642795562744\n",
      "22\n",
      "Norm of latent representation (l2): 11.566293716430664\n",
      "Norm of latent representation (linfty): 1.2652065753936768\n",
      "23\n",
      "Norm of latent representation (l2): 15.567538261413574\n",
      "Norm of latent representation (linfty): 1.6466927528381348\n",
      "24\n",
      "Norm of latent representation (l2): 15.531317710876465\n",
      "Norm of latent representation (linfty): 1.5067131519317627\n",
      "25\n",
      "Norm of latent representation (l2): 14.504332542419434\n",
      "Norm of latent representation (linfty): 1.4050484895706177\n",
      "26\n",
      "Norm of latent representation (l2): 15.419154167175293\n",
      "Norm of latent representation (linfty): 1.8226763010025024\n",
      "27\n",
      "Norm of latent representation (l2): 17.24602508544922\n",
      "Norm of latent representation (linfty): 2.396489381790161\n",
      "28\n",
      "Norm of latent representation (l2): 14.195653915405273\n",
      "Norm of latent representation (linfty): 1.5081340074539185\n",
      "29\n",
      "Norm of latent representation (l2): 14.985218048095703\n",
      "Norm of latent representation (linfty): 1.8624628782272339\n",
      "30\n",
      "Norm of latent representation (l2): 16.940887451171875\n",
      "Norm of latent representation (linfty): 2.2996439933776855\n",
      "31\n",
      "Norm of latent representation (l2): 19.79200553894043\n",
      "Norm of latent representation (linfty): 2.5412943363189697\n",
      "32\n",
      "Norm of latent representation (l2): 15.831937789916992\n",
      "Norm of latent representation (linfty): 1.6499565839767456\n",
      "33\n",
      "Norm of latent representation (l2): 11.572759628295898\n",
      "Norm of latent representation (linfty): 1.5591191053390503\n",
      "34\n",
      "Norm of latent representation (l2): 11.778220176696777\n",
      "Norm of latent representation (linfty): 1.5867335796356201\n",
      "35\n",
      "Norm of latent representation (l2): 22.52336311340332\n",
      "Norm of latent representation (linfty): 2.8236756324768066\n",
      "36\n",
      "Norm of latent representation (l2): 17.753644943237305\n",
      "Norm of latent representation (linfty): 1.870165467262268\n",
      "37\n",
      "Norm of latent representation (l2): 13.779144287109375\n",
      "Norm of latent representation (linfty): 1.6171635389328003\n",
      "38\n",
      "Norm of latent representation (l2): 18.76036834716797\n",
      "Norm of latent representation (linfty): 1.9011013507843018\n",
      "39\n",
      "Norm of latent representation (l2): 13.991966247558594\n",
      "Norm of latent representation (linfty): 1.774382472038269\n",
      "40\n",
      "Norm of latent representation (l2): 17.879806518554688\n",
      "Norm of latent representation (linfty): 1.8782750368118286\n",
      "41\n",
      "Norm of latent representation (l2): 17.4811954498291\n",
      "Norm of latent representation (linfty): 1.9276024103164673\n",
      "42\n",
      "Norm of latent representation (l2): 15.36548137664795\n",
      "Norm of latent representation (linfty): 1.877354621887207\n",
      "43\n",
      "Norm of latent representation (l2): 16.21807289123535\n",
      "Norm of latent representation (linfty): 1.7021913528442383\n",
      "44\n",
      "Norm of latent representation (l2): 24.418718338012695\n",
      "Norm of latent representation (linfty): 3.256965398788452\n",
      "45\n",
      "Norm of latent representation (l2): 12.460742950439453\n",
      "Norm of latent representation (linfty): 1.9800702333450317\n",
      "46\n",
      "Norm of latent representation (l2): 14.649360656738281\n",
      "Norm of latent representation (linfty): 1.7175493240356445\n",
      "47\n",
      "Norm of latent representation (l2): 19.260290145874023\n",
      "Norm of latent representation (linfty): 2.6162049770355225\n",
      "48\n",
      "Norm of latent representation (l2): 18.23499298095703\n",
      "Norm of latent representation (linfty): 2.218829870223999\n",
      "49\n",
      "Norm of latent representation (l2): 15.248056411743164\n",
      "Norm of latent representation (linfty): 1.3794128894805908\n",
      "50\n",
      "Norm of latent representation (l2): 15.908199310302734\n",
      "Norm of latent representation (linfty): 2.069253444671631\n",
      "51\n",
      "Norm of latent representation (l2): 17.893430709838867\n",
      "Norm of latent representation (linfty): 2.372013807296753\n",
      "52\n",
      "Norm of latent representation (l2): 16.711795806884766\n",
      "Norm of latent representation (linfty): 1.6746107339859009\n",
      "53\n",
      "Norm of latent representation (l2): 13.72350788116455\n",
      "Norm of latent representation (linfty): 1.523957371711731\n",
      "54\n",
      "Norm of latent representation (l2): 19.126893997192383\n",
      "Norm of latent representation (linfty): 2.305840253829956\n",
      "55\n",
      "Norm of latent representation (l2): 18.031850814819336\n",
      "Norm of latent representation (linfty): 2.1585865020751953\n",
      "56\n",
      "Norm of latent representation (l2): 16.271474838256836\n",
      "Norm of latent representation (linfty): 1.6216928958892822\n",
      "57\n",
      "Norm of latent representation (l2): 14.635011672973633\n",
      "Norm of latent representation (linfty): 1.619515061378479\n",
      "58\n",
      "Norm of latent representation (l2): 12.150984764099121\n",
      "Norm of latent representation (linfty): 1.2638225555419922\n",
      "59\n",
      "Norm of latent representation (l2): 13.703332901000977\n",
      "Norm of latent representation (linfty): 1.564967393875122\n",
      "60\n",
      "Norm of latent representation (l2): 14.850872993469238\n",
      "Norm of latent representation (linfty): 1.6471798419952393\n",
      "61\n",
      "Norm of latent representation (l2): 23.654325485229492\n",
      "Norm of latent representation (linfty): 3.210376024246216\n",
      "62\n",
      "Norm of latent representation (l2): 16.203105926513672\n",
      "Norm of latent representation (linfty): 1.7896003723144531\n",
      "63\n",
      "Norm of latent representation (l2): 9.946208953857422\n",
      "Norm of latent representation (linfty): 1.1281118392944336\n",
      "64\n",
      "Norm of latent representation (l2): 16.08184051513672\n",
      "Norm of latent representation (linfty): 1.8411744832992554\n",
      "65\n",
      "Norm of latent representation (l2): 18.082372665405273\n",
      "Norm of latent representation (linfty): 1.7687627077102661\n",
      "66\n",
      "Norm of latent representation (l2): 15.259551048278809\n",
      "Norm of latent representation (linfty): 1.506321907043457\n",
      "67\n",
      "Norm of latent representation (l2): 16.591541290283203\n",
      "Norm of latent representation (linfty): 1.7012507915496826\n",
      "68\n",
      "Norm of latent representation (l2): 16.83586883544922\n",
      "Norm of latent representation (linfty): 2.5223593711853027\n",
      "69\n",
      "Norm of latent representation (l2): 16.044300079345703\n",
      "Norm of latent representation (linfty): 2.4788172245025635\n",
      "70\n",
      "Norm of latent representation (l2): 15.843548774719238\n",
      "Norm of latent representation (linfty): 2.3241946697235107\n",
      "71\n",
      "Norm of latent representation (l2): 17.470325469970703\n",
      "Norm of latent representation (linfty): 2.2338757514953613\n",
      "72\n",
      "Norm of latent representation (l2): 16.536575317382812\n",
      "Norm of latent representation (linfty): 2.023592472076416\n",
      "73\n",
      "Norm of latent representation (l2): 17.431167602539062\n",
      "Norm of latent representation (linfty): 2.2990026473999023\n",
      "74\n",
      "Norm of latent representation (l2): 15.40565299987793\n",
      "Norm of latent representation (linfty): 1.835426688194275\n",
      "75\n",
      "Norm of latent representation (l2): 14.759751319885254\n",
      "Norm of latent representation (linfty): 1.4909989833831787\n",
      "76\n",
      "Norm of latent representation (l2): 15.585577011108398\n",
      "Norm of latent representation (linfty): 1.8942817449569702\n",
      "77\n",
      "Norm of latent representation (l2): 17.024127960205078\n",
      "Norm of latent representation (linfty): 1.6356548070907593\n",
      "78\n",
      "Norm of latent representation (l2): 23.1103572845459\n",
      "Norm of latent representation (linfty): 2.968216896057129\n",
      "79\n",
      "Norm of latent representation (l2): 16.83602523803711\n",
      "Norm of latent representation (linfty): 1.879227638244629\n",
      "80\n",
      "Norm of latent representation (l2): 17.5967960357666\n",
      "Norm of latent representation (linfty): 2.141946315765381\n",
      "81\n",
      "Norm of latent representation (l2): 15.999768257141113\n",
      "Norm of latent representation (linfty): 1.6712223291397095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "Norm of latent representation (l2): 16.565305709838867\n",
      "Norm of latent representation (linfty): 1.8230094909667969\n",
      "83\n",
      "Norm of latent representation (l2): 13.94734001159668\n",
      "Norm of latent representation (linfty): 1.7195470333099365\n",
      "84\n",
      "Norm of latent representation (l2): 14.244993209838867\n",
      "Norm of latent representation (linfty): 1.6998398303985596\n",
      "85\n",
      "Norm of latent representation (l2): 11.947233200073242\n",
      "Norm of latent representation (linfty): 1.3817152976989746\n",
      "86\n",
      "Norm of latent representation (l2): 16.665084838867188\n",
      "Norm of latent representation (linfty): 1.9641356468200684\n",
      "87\n",
      "Norm of latent representation (l2): 15.036710739135742\n",
      "Norm of latent representation (linfty): 1.5122132301330566\n",
      "88\n",
      "Norm of latent representation (l2): 15.85049057006836\n",
      "Norm of latent representation (linfty): 1.8467280864715576\n",
      "89\n",
      "Norm of latent representation (l2): 21.591073989868164\n",
      "Norm of latent representation (linfty): 2.64507794380188\n",
      "90\n",
      "Norm of latent representation (l2): 17.82673454284668\n",
      "Norm of latent representation (linfty): 2.1599414348602295\n",
      "91\n",
      "Norm of latent representation (l2): 17.55994987487793\n",
      "Norm of latent representation (linfty): 1.7728853225708008\n",
      "92\n",
      "Norm of latent representation (l2): 15.958409309387207\n",
      "Norm of latent representation (linfty): 1.5455152988433838\n",
      "93\n",
      "Norm of latent representation (l2): 11.90138053894043\n",
      "Norm of latent representation (linfty): 1.3054002523422241\n",
      "94\n",
      "Norm of latent representation (l2): 14.965279579162598\n",
      "Norm of latent representation (linfty): 1.581152081489563\n",
      "95\n",
      "Norm of latent representation (l2): 14.008081436157227\n",
      "Norm of latent representation (linfty): 1.5414425134658813\n",
      "96\n",
      "Norm of latent representation (l2): 19.356809616088867\n",
      "Norm of latent representation (linfty): 2.5393896102905273\n",
      "97\n",
      "Norm of latent representation (l2): 15.441580772399902\n",
      "Norm of latent representation (linfty): 2.19014310836792\n",
      "98\n",
      "Norm of latent representation (l2): 18.65421485900879\n",
      "Norm of latent representation (linfty): 2.1260299682617188\n",
      "99\n",
      "Norm of latent representation (l2): 10.094066619873047\n",
      "Norm of latent representation (linfty): 1.0395967960357666\n"
     ]
    }
   ],
   "source": [
    "samples = cur_batch[0].numpy()\n",
    "labels = cur_batch[1].numpy()\n",
    "latent_differences = []\n",
    "sample_space_differences = []\n",
    "for i in range(batch_size):\n",
    "    x = samples[i, :]\n",
    "    x, z, peturb_x, peturb_z = latent_peturbation_analysis(x, vae)\n",
    "    print(i)\n",
    "    print(f\"Norm of latent representation (l2): {np.linalg.norm(z)}\")\n",
    "    print(f\"Norm of latent representation (linfty): {np.amax(z)}\")\n",
    "    latent_differences.append(np.amax(np.abs(peturb_z - z)))\n",
    "    sample_space_differences.append(np.amax(np.abs(peturb_x - x)))\n",
    "    \n",
    "    \n",
    "# need to figure out why this doesn't look like a Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7030f933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAGbCAYAAAALJa6vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAARvUlEQVR4nO3dfazmeVnf8c9VhzZRUJfuZN0ieKzFh9W6qx1XjaRiqApsLGx9KKsBQjFjFAwmxDiS+BD9Z4yibWrBrLKZ/cNiGgGhWbSQVdlS6sMsjuwuq0Jg1cWVHcQIGJN2lss/zk3OCZnZua8559z3Pee8XsnJuR9+Z35XvvnNmff87qfq7gAAsLx/su4BAACuNgIKAGBIQAEADAkoAIAhAQUAMHRslTu79tpre2tra5W7BAC4Ivfee+9Huvv4xe5baUBtbW3l7Nmzq9wlAMAVqao/v9R9HsIDABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMDQsXUPAFeTrVN3rXuEffPQ6VvWPQLAVcsZKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBg6LIBVVVPrarfqar3VtUDVfWKxe0/WVUfqqpzi6/nHvy4AADrd2yJbS4keWV3v7uqnpTk3qp6++K+X+junzu48QAANs9lA6q7H0nyyOLyx6vqwSRPOejBAAA21eg5UFW1leSrkvz+4qaXV9V7quqOqrrmEj9zsqrOVtXZ8+fP721aAIANsHRAVdUTk7whyQ9198eSvDbJFyW5KdtnqF59sZ/r7tu7+0R3nzh+/PjeJwYAWLOlAqqqnpDtePrV7n5jknT3h7v7se7+ZJJfTnLzwY0JALA5lnkVXiV5XZIHu/vnd91+/a7Nbk1y//6PBwCweZZ5Fd43JHlhkvuq6tzitlclua2qbkrSSR5K8n0HMB8AwMZZ5lV470xSF7nrrfs/DgDA5vNO5AAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBg6LIBVVVPrarfqar3VtUDVfWKxe1Prqq3V9X7Ft+vOfhxAQDWb5kzUBeSvLK7b0jydUleVlU3JDmV5O7ufnqSuxfXAQAOvcsGVHc/0t3vXlz+eJIHkzwlyfOS3LnY7M4kzz+gGQEANsroOVBVtZXkq5L8fpLruvuRxV1/neS6S/zMyao6W1Vnz58/v5dZAQA2wtIBVVVPTPKGJD/U3R/bfV93d5K+2M919+3dfaK7Txw/fnxPwwIAbIKlAqqqnpDtePrV7n7j4uYPV9X1i/uvT/LowYwIALBZlnkVXiV5XZIHu/vnd931liQvXlx+cZI37/94AACb59gS23xDkhcmua+qzi1ue1WS00n+R1W9NMmfJ/muA5kQAGDDXDaguvudSeoSdz9rf8cBANh83okcAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIaOrXsAgL3aOnXXukfYNw+dvmXdIwBLcAYKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADB02YCqqjuq6tGqun/XbT9ZVR+qqnOLr+ce7JgAAJtjmTNQZ5I8+yK3/0J337T4euv+jgUAsLkuG1DdfU+Sj65gFgCAq8KxPfzsy6vqRUnOJnlld//txTaqqpNJTibJ0572tD3sDthPW6fuWvcIAFetK30S+WuTfFGSm5I8kuTVl9qwu2/v7hPdfeL48eNXuDsAgM1xRQHV3R/u7se6+5NJfjnJzfs7FgDA5rqigKqq63ddvTXJ/ZfaFgDgsLnsc6Cq6vVJnpnk2qp6OMlPJHlmVd2UpJM8lOT7Dm5EAIDNctmA6u7bLnLz6w5gFgCAq4J3IgcAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAoWPrHoCjYevUXeseAQD2jTNQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYOjYugcAYMfWqbvWPcK+eOj0LeseAQ6UM1AAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDlw2oqrqjqh6tqvt33fbkqnp7Vb1v8f2agx0TAGBzLHMG6kySZ3/abaeS3N3dT09y9+I6AMCRcNmA6u57knz0025+XpI7F5fvTPL8/R0LAGBzXelzoK7r7kcWl/86yXX7NA8AwMbb85PIu7uT9KXur6qTVXW2qs6eP39+r7sDAFi7Kw2oD1fV9Umy+P7opTbs7tu7+0R3nzh+/PgV7g4AYHNcaUC9JcmLF5dfnOTN+zMOAMDmW+ZtDF6f5P8m+ZKqeriqXprkdJJvrqr3Jfl3i+sAAEfCsctt0N23XeKuZ+3zLAAAVwXvRA4AMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMDQsb38cFU9lOTjSR5LcqG7T+zHUAAAm2xPAbXwTd39kX34cwAArgoewgMAGNprQHWSt1XVvVV18mIbVNXJqjpbVWfPnz+/x90BAKzfXgPqGd391Umek+RlVfVvP32D7r69u09094njx4/vcXcAAOu3p4Dq7g8tvj+a5E1Jbt6PoQAANtkVB1RVfVZVPelTl5N8S5L792swAIBNtZdX4V2X5E1V9ak/579392/ty1QAABvsigOquz+Q5MZ9nAUA4KrgbQwAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIChvbyRJgds69Rd6x4B4Mg7TL+LHzp9y7pHODScgQIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIChY+seYL8dpk/NBoD9dJj+jXzo9C1r3b8zUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAoUP3YcIArN9h+tBauBhnoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAoT0FVFU9u6r+tKreX1Wn9msoAIBNdsUBVVWfkeS/JXlOkhuS3FZVN+zXYAAAm2ovZ6BuTvL+7v5Ad/+/JL+W5Hn7MxYAwOY6toeffUqSv9x1/eEkX/vpG1XVySQnF1c/UVV/uod9Xolrk3xkxfvcVNZih7XYYS12WIsd1mKHtdixMWtRP7OS3XzBpe7YS0AtpbtvT3L7Qe/nUqrqbHefWNf+N4m12GEtdliLHdZih7XYYS12WIsde3kI70NJnrrr+ucvbgMAONT2ElB/mOTpVfWFVfVPk7wgyVv2ZywAgM11xQ/hdfeFqnp5kv+V5DOS3NHdD+zbZPtnbQ8fbiBrscNa7LAWO6zFDmuxw1rssBYL1d3rngEA4KrincgBAIYEFADA0KEIqKq6o6oerar7L3H/91TVe6rqvqp6V1XduOoZV2WJtXjeYi3OVdXZqnrGqmdclcutxa7tvqaqLlTVd6xqtlVb4rh4ZlX93eK4OFdVP77qGVdlmeNisR7nquqBqnrHKudbpSWOix/edUzcX1WPVdWTVz3nKiyxFp9TVf+zqv54cVy8ZNUzrsoSa3FNVb1p8W/JH1TVV6x6xk1wKAIqyZkkz36c+z+Y5Bu7+18n+ekc7ifBncnjr8XdSW7s7puS/Kckv7KCmdblTB5/LT71kUQ/k+Rtqxhojc7kMmuR5H93902Lr59awUzrciaPsxZV9blJXpPk33f3lyf5ztWMtRZn8jhr0d0/+6ljIsmPJnlHd390RbOt2pk8/t+RlyV5b3ffmOSZSV69eAX6YXQmj78Wr0pyrru/MsmLkvyXVQy1aQ5FQHX3PUku+Ze6u9/V3X+7uPp72X7PqkNpibX4RO+8cuCzkhzaVxFcbi0WfjDJG5I8evATrc+Sa3EkLLEW353kjd39F4vtD+2xMTwubkvy+gMcZ62WWItO8qSqqiRPXGx7YRWzrdoSa3FDkt9ebPsnSbaq6rpVzLZJDkVADb00yW+ue4h1qqpbq+pPktyV7bNQR1JVPSXJrUleu+5ZNsTXLx6e+M2q+vJ1D7NGX5zkmqr63aq6t6petO6B1q2qPjPbZyTesO5Z1ugXk3xZkr9Kcl+SV3T3J9c70tr8cZL/kCRVdXO2P+7k0J6YuJQjFVBV9U3ZDqgfWfcs69Tdb+ruL03y/Gw/pHlU/eckP3KEfwnu9u4kX7B4eOK/JvmN9Y6zVseS/JsktyT51iQ/VlVfvN6R1u7bkvyfQ/zw3TK+Ncm5JP8iyU1JfrGqPnudA63R6SSfW1Xnsn0W/4+SPLbWidbgwD8Lb1NU1Vdm+/k+z+nuv1n3PJugu++pqn9ZVdd290Z8OOSKnUjya9tn5HNtkudW1YXu/o21TrUG3f2xXZffWlWvOcLHxcNJ/qa7/z7J31fVPUluTPJn6x1rrV6QQ/zw3ZJekuT04ikQ76+qDyb50iR/sN6xVm/x++IlSbJ4SPODST6w1qHW4EicgaqqpyV5Y5IXdvdR/iWYqvpXiwM+VfXVSf5ZkiMZlN39hd291d1bSX49yQ8cxXhKkqr6vF3Hxc3Z/t1wJI+LJG9O8oyqOrZ46Oprkzy45pnWpqo+J8k3ZntdjrK/SPKsJFk83+dLcgSjIdl+ocWuJ9B/b5J7dv8n7Kg4FGegqur12X5VxLVV9XCSn0jyhCTp7l9K8uNJ/nmS1yz+jbhwWD9Neom1+PYkL6qq/5/kH5L8x11PKj9UlliLI2OJtfiOJN9fVReyfVy84KgeF939YFX9VpL3JPlkkl/p7sd9K4yr1ZJ/R25N8rbFGblDa4m1+OkkZ6rqviSV7Yf/D+UZ2iXW4suS3FlVneSBbD815sjxUS4AAENH4iE8AID9JKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADP0jYWpuU0YQzp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these are differences between the original sample, and the corruption obtained by peturbing the latent representation\n",
    "# and feeding this to the decoder \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x_differences = np.array(sample_space_differences)\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(x_differences)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9500bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_differences = np.array(latent_differences)\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(z_differences)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b97b3b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7fbb68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 4)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peturb_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53e2864d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c4419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
